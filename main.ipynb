{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49fca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>Location#Transportation</th>\n",
       "      <th>Location#Downtown</th>\n",
       "      <th>Location#Easy_to_find</th>\n",
       "      <th>Service#Queue</th>\n",
       "      <th>Service#Hospitality</th>\n",
       "      <th>Service#Parking</th>\n",
       "      <th>Service#Timely</th>\n",
       "      <th>...</th>\n",
       "      <th>Price#Cost_effective</th>\n",
       "      <th>Price#Discount</th>\n",
       "      <th>Ambience#Decoration</th>\n",
       "      <th>Ambience#Noise</th>\n",
       "      <th>Ambience#Space</th>\n",
       "      <th>Ambience#Sanitary</th>\n",
       "      <th>Food#Portion</th>\n",
       "      <th>Food#Taste</th>\n",
       "      <th>Food#Appearance</th>\n",
       "      <th>Food#Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28729</td>\n",
       "      <td>【正新（金冠店）】位于株洲市芦淞区火车站商圈火车站正对面，地理位置很火，像他们家这种接地气的...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19856</td>\n",
       "      <td>平安夜晚上路过附近，搜了点评觉得看起来不错就进去了。感觉像酒吧，灯光七彩摇曳，音乐劲爆，据说...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41565</td>\n",
       "      <td>非常正宗的日本料理店！早就知道上井日本料理店了，一直没机会去，这一次和老公两人团了两张优惠券...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5834</td>\n",
       "      <td>今天非常棒棒嗒，来到阿川吃饭饭，一直就听他们家的名气很大，但是一直未能过品尝一下。今天有幸来...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36184</td>\n",
       "      <td>让接送的人等了半个小时非常不好意思，来了之后只有我们一桌了。服务非常好，老板亲自帮我们点菜，...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             review  star  \\\n",
       "0  28729  【正新（金冠店）】位于株洲市芦淞区火车站商圈火车站正对面，地理位置很火，像他们家这种接地气的...   4.0   \n",
       "1  19856  平安夜晚上路过附近，搜了点评觉得看起来不错就进去了。感觉像酒吧，灯光七彩摇曳，音乐劲爆，据说...   3.0   \n",
       "2  41565  非常正宗的日本料理店！早就知道上井日本料理店了，一直没机会去，这一次和老公两人团了两张优惠券...   5.0   \n",
       "3   5834  今天非常棒棒嗒，来到阿川吃饭饭，一直就听他们家的名气很大，但是一直未能过品尝一下。今天有幸来...   5.0   \n",
       "4  36184  让接送的人等了半个小时非常不好意思，来了之后只有我们一桌了。服务非常好，老板亲自帮我们点菜，...   5.0   \n",
       "\n",
       "   Location#Transportation  Location#Downtown  Location#Easy_to_find  \\\n",
       "0                       -2                  1                      1   \n",
       "1                       -2                 -2                     -2   \n",
       "2                       -2                 -2                     -2   \n",
       "3                       -2                 -2                     -2   \n",
       "4                       -2                 -2                     -2   \n",
       "\n",
       "   Service#Queue  Service#Hospitality  Service#Parking  Service#Timely  ...  \\\n",
       "0              0                   -2               -2              -2  ...   \n",
       "1             -1                   -2               -2              -1  ...   \n",
       "2             -2                   -2               -2              -2  ...   \n",
       "3             -2                    1               -2              -2  ...   \n",
       "4             -2                    1               -2               1  ...   \n",
       "\n",
       "   Price#Cost_effective  Price#Discount  Ambience#Decoration  Ambience#Noise  \\\n",
       "0                    -2               0                   -2              -2   \n",
       "1                    -2              -2                   -1              -1   \n",
       "2                    -2               0                    1               1   \n",
       "3                    -2              -2                    1               1   \n",
       "4                    -2              -2                   -2              -2   \n",
       "\n",
       "   Ambience#Space  Ambience#Sanitary  Food#Portion  Food#Taste  \\\n",
       "0              -2                 -2            -2           0   \n",
       "1              -2                 -2            -1           0   \n",
       "2               1                  1            -2           1   \n",
       "3               1                  1            -2           1   \n",
       "4              -2                 -2            -2           1   \n",
       "\n",
       "   Food#Appearance  Food#Recommend  \n",
       "0               -2               0  \n",
       "1               -2              -2  \n",
       "2               -2               1  \n",
       "3               -2               1  \n",
       "4               -2              -2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dev = pd.read_csv(r'C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\dev.csv')\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6c738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4940, 21)\n",
      "103740\n",
      "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
      "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
      "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
      "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
      "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
      "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dev.shape)\n",
    "print(dev.size)\n",
    "print(dev.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a95be03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>Location#Transportation</th>\n",
       "      <th>Location#Downtown</th>\n",
       "      <th>Location#Easy_to_find</th>\n",
       "      <th>Service#Queue</th>\n",
       "      <th>Service#Hospitality</th>\n",
       "      <th>Service#Parking</th>\n",
       "      <th>Service#Timely</th>\n",
       "      <th>...</th>\n",
       "      <th>Price#Cost_effective</th>\n",
       "      <th>Price#Discount</th>\n",
       "      <th>Ambience#Decoration</th>\n",
       "      <th>Ambience#Noise</th>\n",
       "      <th>Ambience#Space</th>\n",
       "      <th>Ambience#Sanitary</th>\n",
       "      <th>Food#Portion</th>\n",
       "      <th>Food#Taste</th>\n",
       "      <th>Food#Appearance</th>\n",
       "      <th>Food#Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13482</td>\n",
       "      <td>和老公的朋友们聚餐，选择了这家烧肉屋，据说人气很旺，于是定座的，我们坐在楼上，阁楼感觉有点空...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25634</td>\n",
       "      <td>昨天晚上想找个安静的环境和同事谈工作，去了绿茵阁。我是第一次到该店，一进去感觉很温馨，环境优...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6383</td>\n",
       "      <td>以前听朋友说超级推荐 然后她又在野餐的时候买了这里的瘦身沙拉 我就更加期待 因为平时不在这一...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46407</td>\n",
       "      <td>看到大众点评网的推荐来试试看，在意大利餐厅吃泰国菜虽然说是创意泰菜，也只是摆盘更多变、时尚，...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715</td>\n",
       "      <td>在清迈我唯一推荐的一家餐厅，非常非常正宗的泰北菜。叫做河岸餐厅顾名思义就在河边，我建议傍晚的...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             review  star  \\\n",
       "0  13482  和老公的朋友们聚餐，选择了这家烧肉屋，据说人气很旺，于是定座的，我们坐在楼上，阁楼感觉有点空...   4.0   \n",
       "1  25634  昨天晚上想找个安静的环境和同事谈工作，去了绿茵阁。我是第一次到该店，一进去感觉很温馨，环境优...   4.0   \n",
       "2   6383  以前听朋友说超级推荐 然后她又在野餐的时候买了这里的瘦身沙拉 我就更加期待 因为平时不在这一...   5.0   \n",
       "3  46407  看到大众点评网的推荐来试试看，在意大利餐厅吃泰国菜虽然说是创意泰菜，也只是摆盘更多变、时尚，...   4.0   \n",
       "4  15715  在清迈我唯一推荐的一家餐厅，非常非常正宗的泰北菜。叫做河岸餐厅顾名思义就在河边，我建议傍晚的...   5.0   \n",
       "\n",
       "   Location#Transportation  Location#Downtown  Location#Easy_to_find  \\\n",
       "0                       -2                 -2                     -2   \n",
       "1                       -2                 -2                     -2   \n",
       "2                       -2                 -2                     -2   \n",
       "3                       -2                 -2                     -2   \n",
       "4                       -2                 -2                     -2   \n",
       "\n",
       "   Service#Queue  Service#Hospitality  Service#Parking  Service#Timely  ...  \\\n",
       "0             -2                   -2               -2              -2  ...   \n",
       "1             -2                    0               -2              -2  ...   \n",
       "2             -2                    0               -2              -2  ...   \n",
       "3             -2                   -2               -2              -2  ...   \n",
       "4              0                    1               -2              -2  ...   \n",
       "\n",
       "   Price#Cost_effective  Price#Discount  Ambience#Decoration  Ambience#Noise  \\\n",
       "0                    -2              -2                    0              -2   \n",
       "1                    -2              -2                    1               1   \n",
       "2                     1              -2                    1              -2   \n",
       "3                     0              -2                    1              -2   \n",
       "4                    -2              -2                    1              -2   \n",
       "\n",
       "   Ambience#Space  Ambience#Sanitary  Food#Portion  Food#Taste  \\\n",
       "0              -2                 -2             1           1   \n",
       "1               1                 -2            -2           1   \n",
       "2              -2                 -2            -2           1   \n",
       "3              -2                 -2             0           1   \n",
       "4              -2                 -2            -2           1   \n",
       "\n",
       "   Food#Appearance  Food#Recommend  \n",
       "0               -2              -2  \n",
       "1               -2              -2  \n",
       "2               -2              -2  \n",
       "3                1              -2  \n",
       "4                1               1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r'C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed6268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4940, 21)\n",
      "103740\n",
      "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
      "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
      "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
      "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
      "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
      "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test.size)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f61a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>Location#Transportation</th>\n",
       "      <th>Location#Downtown</th>\n",
       "      <th>Location#Easy_to_find</th>\n",
       "      <th>Service#Queue</th>\n",
       "      <th>Service#Hospitality</th>\n",
       "      <th>Service#Parking</th>\n",
       "      <th>Service#Timely</th>\n",
       "      <th>...</th>\n",
       "      <th>Price#Cost_effective</th>\n",
       "      <th>Price#Discount</th>\n",
       "      <th>Ambience#Decoration</th>\n",
       "      <th>Ambience#Noise</th>\n",
       "      <th>Ambience#Space</th>\n",
       "      <th>Ambience#Sanitary</th>\n",
       "      <th>Food#Portion</th>\n",
       "      <th>Food#Taste</th>\n",
       "      <th>Food#Appearance</th>\n",
       "      <th>Food#Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46277</td>\n",
       "      <td>状元楼饭店第一次去，因为地理位置优越：在宁波市和义大道高、大、上，里面装修中式，菜是地道的宁...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23691</td>\n",
       "      <td>我最爱他们家的猪手，麻辣鸡爪，肉片口磨，道道菜都是家常菜的味道，非常的好吃，是原来的昊烨，和...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23660</td>\n",
       "      <td>我是比较喜欢荣新馆的，因为材料新鲜，服务又好，价格适中，但是老公每次吃都会拉肚子，特神奇，我...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379</td>\n",
       "      <td>8.8秒杀的多嘴肉蟹煲，第一天开业就去了，大众点评很给力，排了两个半小时的队才轮到，他家很年...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13811</td>\n",
       "      <td>喜欢KOI好多年了，但是看着它的价格在一路飙涨，真心是有点越来越爱不起来了呢。不过还好有大众...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             review  star  \\\n",
       "0  46277  状元楼饭店第一次去，因为地理位置优越：在宁波市和义大道高、大、上，里面装修中式，菜是地道的宁...   5.0   \n",
       "1  23691  我最爱他们家的猪手，麻辣鸡爪，肉片口磨，道道菜都是家常菜的味道，非常的好吃，是原来的昊烨，和...   5.0   \n",
       "2  23660  我是比较喜欢荣新馆的，因为材料新鲜，服务又好，价格适中，但是老公每次吃都会拉肚子，特神奇，我...   4.0   \n",
       "3    379  8.8秒杀的多嘴肉蟹煲，第一天开业就去了，大众点评很给力，排了两个半小时的队才轮到，他家很年...   5.0   \n",
       "4  13811  喜欢KOI好多年了，但是看着它的价格在一路飙涨，真心是有点越来越爱不起来了呢。不过还好有大众...   5.0   \n",
       "\n",
       "   Location#Transportation  Location#Downtown  Location#Easy_to_find  \\\n",
       "0                        1                  1                      1   \n",
       "1                        1                 -2                     -2   \n",
       "2                       -2                 -2                     -2   \n",
       "3                       -2                 -2                     -2   \n",
       "4                       -2                  1                     -1   \n",
       "\n",
       "   Service#Queue  Service#Hospitality  Service#Parking  Service#Timely  ...  \\\n",
       "0             -2                    1               -2              -2  ...   \n",
       "1             -2                    1               -2              -2  ...   \n",
       "2             -2                    1               -2              -2  ...   \n",
       "3             -1                    1               -2              -2  ...   \n",
       "4             -2                   -2               -2              -2  ...   \n",
       "\n",
       "   Price#Cost_effective  Price#Discount  Ambience#Decoration  Ambience#Noise  \\\n",
       "0                    -2              -2                    1              -2   \n",
       "1                    -2              -2                   -2              -2   \n",
       "2                    -2              -2                   -2              -2   \n",
       "3                    -2               1                   -2              -2   \n",
       "4                    -2               1                   -2              -2   \n",
       "\n",
       "   Ambience#Space  Ambience#Sanitary  Food#Portion  Food#Taste  \\\n",
       "0              -2                 -2            -2           1   \n",
       "1              -2                  1            -2           1   \n",
       "2              -2                 -2            -2           0   \n",
       "3              -2                 -2             1           1   \n",
       "4              -2                 -2             1           1   \n",
       "\n",
       "   Food#Appearance  Food#Recommend  \n",
       "0               -2              -2  \n",
       "1               -2              -2  \n",
       "2                1              -2  \n",
       "3               -2              -2  \n",
       "4               -2              -2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv(r'C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1616e88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36850, 21)\n",
      "773850\n",
      "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
      "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
      "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
      "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
      "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
      "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train.size)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa94cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown',\n",
       "       'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality',\n",
       "       'Service#Parking', 'Service#Timely', 'Price#Level',\n",
       "       'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration',\n",
       "       'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion',\n",
       "       'Food#Taste', 'Food#Appearance', 'Food#Recommend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21bd20f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'review', 'star', 'Location#Transportation', 'Location#Downtown', 'Location#Easy_to_find', 'Service#Queue', 'Service#Hospitality', 'Service#Parking', 'Service#Timely', 'Price#Level', 'Price#Cost_effective', 'Price#Discount', 'Ambience#Decoration', 'Ambience#Noise', 'Ambience#Space', 'Ambience#Sanitary', 'Food#Portion', 'Food#Taste', 'Food#Appearance', 'Food#Recommend']\n",
      "                                                                         0  \\\n",
      "id                                                                   46277   \n",
      "review                   状元楼饭店第一次去，因为地理位置优越：在宁波市和义大道高、大、上，里面装修中式，菜是地道的宁...   \n",
      "star                                                                   5.0   \n",
      "Location#Transportation                                                  1   \n",
      "Location#Downtown                                                        1   \n",
      "Location#Easy_to_find                                                    1   \n",
      "Service#Queue                                                           -2   \n",
      "Service#Hospitality                                                      1   \n",
      "Service#Parking                                                         -2   \n",
      "Service#Timely                                                          -2   \n",
      "Price#Level                                                             -2   \n",
      "Price#Cost_effective                                                    -2   \n",
      "Price#Discount                                                          -2   \n",
      "Ambience#Decoration                                                      1   \n",
      "Ambience#Noise                                                          -2   \n",
      "Ambience#Space                                                          -2   \n",
      "Ambience#Sanitary                                                       -2   \n",
      "Food#Portion                                                            -2   \n",
      "Food#Taste                                                               1   \n",
      "Food#Appearance                                                         -2   \n",
      "Food#Recommend                                                          -2   \n",
      "\n",
      "                                                                         1  \\\n",
      "id                                                                   23691   \n",
      "review                   我最爱他们家的猪手，麻辣鸡爪，肉片口磨，道道菜都是家常菜的味道，非常的好吃，是原来的昊烨，和...   \n",
      "star                                                                   5.0   \n",
      "Location#Transportation                                                  1   \n",
      "Location#Downtown                                                       -2   \n",
      "Location#Easy_to_find                                                   -2   \n",
      "Service#Queue                                                           -2   \n",
      "Service#Hospitality                                                      1   \n",
      "Service#Parking                                                         -2   \n",
      "Service#Timely                                                          -2   \n",
      "Price#Level                                                             -2   \n",
      "Price#Cost_effective                                                    -2   \n",
      "Price#Discount                                                          -2   \n",
      "Ambience#Decoration                                                     -2   \n",
      "Ambience#Noise                                                          -2   \n",
      "Ambience#Space                                                          -2   \n",
      "Ambience#Sanitary                                                        1   \n",
      "Food#Portion                                                            -2   \n",
      "Food#Taste                                                               1   \n",
      "Food#Appearance                                                         -2   \n",
      "Food#Recommend                                                          -2   \n",
      "\n",
      "                                                                         2  \n",
      "id                                                                   23660  \n",
      "review                   我是比较喜欢荣新馆的，因为材料新鲜，服务又好，价格适中，但是老公每次吃都会拉肚子，特神奇，我...  \n",
      "star                                                                   4.0  \n",
      "Location#Transportation                                                 -2  \n",
      "Location#Downtown                                                       -2  \n",
      "Location#Easy_to_find                                                   -2  \n",
      "Service#Queue                                                           -2  \n",
      "Service#Hospitality                                                      1  \n",
      "Service#Parking                                                         -2  \n",
      "Service#Timely                                                          -2  \n",
      "Price#Level                                                              0  \n",
      "Price#Cost_effective                                                    -2  \n",
      "Price#Discount                                                          -2  \n",
      "Ambience#Decoration                                                     -2  \n",
      "Ambience#Noise                                                          -2  \n",
      "Ambience#Space                                                          -2  \n",
      "Ambience#Sanitary                                                       -2  \n",
      "Food#Portion                                                            -2  \n",
      "Food#Taste                                                               0  \n",
      "Food#Appearance                                                          1  \n",
      "Food#Recommend                                                          -2  \n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", train.columns.tolist())\n",
    "\n",
    "print(train.head(3).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b625fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f608a9f5",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8187154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laksh\\miniconda3\\envs\\asap_light\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51da6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Config =====\n",
    "DATA_DIR = Path(r\"C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\")\n",
    "MAX_LEN = 256           # reduce if GPU memory is low\n",
    "MODEL_NAME = \"hfl/chinese-roberta-wwm-ext\"  # teacher backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b0abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laksh\\miniconda3\\envs\\asap_light\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\laksh\\.cache\\huggingface\\hub\\models--hfl--chinese-roberta-wwm-ext. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "ASPECT_COLUMNS = [\n",
    "    \"Location#Transportation\",\"Location#Downtown\",\"Location#Easy_to_find\",\n",
    "    \"Service#Queue\",\"Service#Hospitality\",\"Service#Parking\",\"Service#Timely\",\n",
    "    \"Price#Level\",\"Price#Cost_effective\",\"Price#Discount\",\n",
    "    \"Ambience#Decoration\",\"Ambience#Noise\",\"Ambience#Space\",\"Ambience#Sanitary\",\n",
    "    \"Food#Portion\",\"Food#Taste\",\"Food#Appearance\",\"Food#Recommend\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72eed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process(split):\n",
    "    df = pd.read_csv(DATA_DIR / f\"{split}.csv\")\n",
    "    print(f\"{split}: {df.shape}\")\n",
    "    \n",
    "    # Convert -2 => mask, map others to 0/1/2\n",
    "    masks = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        mask = []\n",
    "        lab = []\n",
    "        for col in ASPECT_COLUMNS:\n",
    "            val = int(row[col])\n",
    "            if val == -2:\n",
    "                mask.append(0)\n",
    "                lab.append(0)       # placeholder (ignored later)\n",
    "            else:\n",
    "                mask.append(1)\n",
    "                # map {-1,0,1} -> {0,1,2}\n",
    "                lab.append(val + 1)\n",
    "        masks.append(mask)\n",
    "        labels.append(lab)\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        df[\"review\"].tolist(),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"],\n",
    "        \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        \"aspect_labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        \"aspect_masks\": torch.tensor(masks, dtype=torch.float),\n",
    "        \"star\": torch.tensor(df[\"star\"].astype(int).values, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba2423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (36850, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36850/36850 [00:01<00:00, 32856.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev: (4940, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4940/4940 [00:00<00:00, 38305.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (4940, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4940/4940 [00:00<00:00, 37227.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed tensors saved.\n"
     ]
    }
   ],
   "source": [
    "train_data = load_and_process(\"train\")\n",
    "dev_data   = load_and_process(\"dev\")\n",
    "test_data  = load_and_process(\"test\")\n",
    "\n",
    "torch.save({\"train\": train_data, \"dev\": dev_data, \"test\": test_data},\n",
    "           DATA_DIR / \"asap_preprocessed.pt\")\n",
    "print(\"Preprocessed tensors saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bedfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_teacher.py\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Corrected transformers import: removed AdamW\n",
    "from transformers import AutoModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW # <-- Corrected AdamW import\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2950a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# # Config / Hyperparameters\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_pt\", type=str,\n",
    "                    default=r\"C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\asap_preprocessed.pt\",\n",
    "                    help=\"Path to the preprocessed asap_preprocessed.pt\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"hfl/chinese-roberta-wwm-ext\")\n",
    "parser.add_argument(\"--max_len\", type=int, default=256)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "parser.add_argument(\"--lr\", type=float, default=2e-5)\n",
    "parser.add_argument(\"--epochs\", type=int, default=5)\n",
    "parser.add_argument(\"--grad_accum\", type=int, default=1)\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.01)\n",
    "parser.add_argument(\"--warmup_ratio\", type=float, default=0.06)\n",
    "parser.add_argument(\"--rating_head\", action=\"store_true\",\n",
    "                    help=\"Enable rating (star) prediction head. Optional.\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default=\"./checkpoints_teacher\")\n",
    "\n",
    "# CRITICAL FIX for notebooks/interactive sessions: \n",
    "# Pass an empty list [] to parse_args() to use default values and avoid SystemExit: 2\n",
    "args = parser.parse_args([])\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aac98f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset wrapper\n",
    "\n",
    "class ASAPDataset(Dataset):\n",
    "    def __init__(self, tensors):\n",
    "        # tensors: dict with keys input_ids, attention_mask, aspect_labels, aspect_masks, star\n",
    "        self.input_ids = tensors[\"input_ids\"]\n",
    "        self.attn = tensors[\"attention_mask\"]\n",
    "        self.aspect_labels = tensors[\"aspect_labels\"]\n",
    "        self.aspect_masks = tensors[\"aspect_masks\"]\n",
    "        self.star = tensors.get(\"star\", None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attn[idx],\n",
    "            \"aspect_labels\": self.aspect_labels[idx],\n",
    "            \"aspect_masks\": self.aspect_masks[idx]\n",
    "        }\n",
    "        if self.star is not None:\n",
    "            item[\"star\"] = self.star[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c21b0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class TeacherACSA(nn.Module):\n",
    "    def __init__(self, model_name, num_aspects=18, hidden_size=768, rating_head=False):\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        d = self.config.hidden_size if hasattr(self.config, \"hidden_size\") else hidden_size\n",
    "        self.num_aspects = num_aspects\n",
    "        # Aspect attention params (we use a small shared W_a and per-aspect omega and Wp optional)\n",
    "        # To reduce params, we implement a shared W_a and per-aspect vector ω_i\n",
    "        self.W_a = nn.Linear(d, d)  # tanh(W_a H) computed token-wise\n",
    "        # per-aspect vector to compute attention scores\n",
    "        self.omega = nn.Parameter(torch.randn(num_aspects, d) * 0.02)\n",
    "        # projection for attentive r_i (optional tanh)\n",
    "        self.W_p = nn.Linear(d, d)\n",
    "        # classifiers: per-aspect linear -> 3 classes\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(d, 3) for _ in range(num_aspects)])\n",
    "        # rating head (optional)\n",
    "        self.rating_head = rating_head\n",
    "        if rating_head:\n",
    "            self.rating_dense = nn.Linear(d, d)\n",
    "            self.rating_pred = nn.Linear(d, 5)  # 1-5 stars\n",
    "        # init\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # small init for attention omegas already done; init others lightly\n",
    "        for m in self.classifiers:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.W_a.weight)\n",
    "        nn.init.zeros_(self.W_a.bias)\n",
    "        nn.init.xavier_uniform_(self.W_p.weight)\n",
    "        nn.init.zeros_(self.W_p.bias)\n",
    "        if self.rating_head:\n",
    "            nn.init.xavier_uniform_(self.rating_dense.weight)\n",
    "            nn.init.zeros_(self.rating_dense.bias)\n",
    "            nn.init.xavier_uniform_(self.rating_pred.weight)\n",
    "            nn.init.zeros_(self.rating_pred.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        # sequence_output: [batch, seq_len, d]\n",
    "        seq = outputs.last_hidden_state  # (B, L, d)\n",
    "        B, L, d = seq.size()\n",
    "\n",
    "        # compute Ma = tanh(W_a H) -> (B, L, d)\n",
    "        Ma = torch.tanh(self.W_a(seq))  # (B, L, d)\n",
    "        # compute attention weights for each aspect:\n",
    "        # ω_i^T Ma (over d) -> (num_aspects, B, L) then softmax over L\n",
    "        # we compute batch-wise: (B, num_aspects, L)\n",
    "        # omega: (num_aspects, d) -> (1, num_aspects, d)\n",
    "        omega = self.omega.unsqueeze(0)  # (1, A, d)\n",
    "        # Ma: (B, L, d) -> (B, 1, L, d)\n",
    "        # compute attention scores\n",
    "        # Ma: (B, L, d), omega: (A, d)\n",
    "        attn_scores = torch.matmul(Ma, self.omega.t())  # (B, L, A)\n",
    "        attn_scores = attn_scores.permute(0, 2, 1)      # (B, A, L)\n",
    "\n",
    "        # The einsum above is tricky; simpler compute with matmul:\n",
    "        # attn_scores = torch.matmul(Ma, omega.transpose(0,1))  # (B, L, A)\n",
    "        # then permute to (B,A,L)\n",
    "        # but to avoid confusion, let's do this simpler:\n",
    "        # --> we'll recompute attn_scores below to ensure correctness\n",
    "\n",
    "        # safer path:\n",
    "        # Ma: (B, L, d), omega: (A, d) -> scores (B, L, A)\n",
    "        attn_scores2 = torch.matmul(Ma, self.omega.t())  # (B, L, A)\n",
    "        attn_scores2 = attn_scores2.permute(0, 2, 1)     # (B, A, L)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores2, dim=-1)  # over L\n",
    "\n",
    "        # attentive sum: r_i = tanh(W_p * (H * alpha^T))\n",
    "        # compute weighted sum: (B, A, L) @ (B, L, d) -> (B, A, d)\n",
    "        r = torch.einsum(\"bal,bld->bad\", attn_weights, seq)  # (B, A, d)\n",
    "        r = torch.tanh(self.W_p(r))  # (B, A, d)\n",
    "\n",
    "        # compute logits per aspect\n",
    "        logits = []\n",
    "        for i in range(self.num_aspects):\n",
    "            logits_i = self.classifiers[i](r[:, i, :])  # (B, 3)\n",
    "            logits.append(logits_i.unsqueeze(1))\n",
    "        logits = torch.cat(logits, dim=1)  # (B, A, 3)\n",
    "\n",
    "        rating_logits = None\n",
    "        if self.rating_head:\n",
    "            cls = outputs.pooler_output if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None else outputs.last_hidden_state[:, 0, :]\n",
    "            rating_repr = torch.tanh(self.rating_dense(cls))\n",
    "            rating_logits = self.rating_pred(rating_repr)  # (B, 5)\n",
    "\n",
    "        return logits, rating_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f4d2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils: masked loss, metrics\n",
    "\n",
    "def masked_aspect_loss(logits, labels, masks, device):\n",
    "    # logits: (B, A, 3), labels: (B, A) in {0,1,2}, masks: (B, A) float {0,1}\n",
    "    B, A, C = logits.size()\n",
    "    logits_flat = logits.view(-1, C)            # (B*A, 3)\n",
    "    labels_flat = labels.view(-1)               # (B*A,)\n",
    "    masks_flat = masks.view(-1)                 # (B*A,)\n",
    "    # only keep indices with mask==1\n",
    "    keep = masks_flat.nonzero(as_tuple=False).squeeze(1)\n",
    "    if keep.numel() == 0:\n",
    "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    logits_keep = logits_flat[keep]\n",
    "    labels_keep = labels_flat[keep]\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(logits_keep, labels_keep)\n",
    "    return loss\n",
    "\n",
    "def masked_metrics(logits, labels, masks):\n",
    "    # return macro_f1 and acc across all mentioned aspect positions\n",
    "    # flatten\n",
    "    logits_flat = logits.detach().cpu().numpy()  # (B, A, 3)\n",
    "    preds = logits_flat.argmax(axis=-1).reshape(-1)  # (B*A,)\n",
    "    labels_flat = labels.detach().cpu().numpy().reshape(-1)\n",
    "    masks_flat = masks.detach().cpu().numpy().reshape(-1)\n",
    "    keep_idx = masks_flat == 1\n",
    "    if keep_idx.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "    y_true = labels_flat[keep_idx]\n",
    "    y_pred = preds[keep_idx]\n",
    "    # Macro-F1 across classes 0/1/2\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57d88290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:62: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "Epoch 1:   0%|          | 0/2304 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 1: 100%|██████████| 2304/2304 [57:15<00:00,  1.49s/it, loss=0.58] \n",
      "Eval: 100%|██████████| 309/309 [05:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 DEV loss 0.4607 F1 0.7376 Acc 0.8114\n",
      "Saved best model to checkpoints_teacher\\best_teacher.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/2304 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 2: 100%|██████████| 2304/2304 [44:08<00:00,  1.15s/it, loss=0.408]\n",
      "Eval: 100%|██████████| 309/309 [05:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 DEV loss 0.4472 F1 0.7534 Acc 0.8174\n",
      "Saved best model to checkpoints_teacher\\best_teacher.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/2304 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 3: 100%|██████████| 2304/2304 [44:17<00:00,  1.15s/it, loss=0.307]\n",
      "Eval: 100%|██████████| 309/309 [05:21<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 DEV loss 0.4617 F1 0.7544 Acc 0.8200\n",
      "Saved best model to checkpoints_teacher\\best_teacher.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/2304 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 4: 100%|██████████| 2304/2304 [44:17<00:00,  1.15s/it, loss=0.198]\n",
      "Eval: 100%|██████████| 309/309 [05:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 DEV loss 0.5325 F1 0.7534 Acc 0.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/2304 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_26068\\1820729157.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 5: 100%|██████████| 2304/2304 [44:17<00:00,  1.15s/it, loss=0.116]\n",
      "Eval: 100%|██████████| 309/309 [05:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 DEV loss 0.6128 F1 0.7482 Acc 0.8115\n",
      "Loading best model for TEST eval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 309/309 [09:05<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST loss 0.4600 F1 0.7590 Acc 0.8223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training & evaluation\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_loss = 0.0\n",
    "    device = next(model.parameters()).device\n",
    "    total_steps = 0\n",
    "    all_f1 = []\n",
    "    all_acc = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Eval\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attn = batch[\"attention_mask\"].to(device)\n",
    "            aspect_labels = batch[\"aspect_labels\"].to(device)\n",
    "            aspect_masks = batch[\"aspect_masks\"].to(device)\n",
    "            logits, rating_logits = model(input_ids, attn)\n",
    "            loss = masked_aspect_loss(logits, aspect_labels, aspect_masks, device)\n",
    "            f1, acc = masked_metrics(logits, aspect_labels, aspect_masks)\n",
    "            all_f1.append((f1, (aspect_masks.sum().cpu().item())))\n",
    "            all_acc.append((acc, (aspect_masks.sum().cpu().item())))\n",
    "            all_loss += loss.item()\n",
    "            total_steps += 1\n",
    "    # average metrics weighted by aspect count\n",
    "    # simpler: compute mean of f1 across batches\n",
    "    mean_loss = all_loss / max(1, total_steps)\n",
    "    # weighted average: weight by mentioned aspect counts per batch\n",
    "    # here we just compute simple average\n",
    "    mean_f1 = np.mean([x[0] for x in all_f1]) if all_f1 else 0.0\n",
    "    mean_acc = np.mean([x[0] for x in all_acc]) if all_acc else 0.0\n",
    "    return mean_loss, mean_f1, mean_acc\n",
    "\n",
    "def train():\n",
    "    # load preprocessed\n",
    "    data = torch.load(args.data_pt)\n",
    "    train_ds = ASAPDataset(data[\"train\"])\n",
    "    dev_ds = ASAPDataset(data[\"dev\"])\n",
    "    test_ds = ASAPDataset(data[\"test\"])\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, drop_last=False)\n",
    "    dev_loader = DataLoader(dev_ds, batch_size=args.batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    model = TeacherACSA(args.model_name, num_aspects=18, rating_head=args.rating_head)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # optimizer and scheduler\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr, eps=1e-8)\n",
    "    total_steps = len(train_loader) // args.grad_accum * args.epochs\n",
    "    warmup_steps = int(total_steps * args.warmup_ratio)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    best_dev_f1 = -1.0\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for step, batch in enumerate(pbar, start=1):\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attn = batch[\"attention_mask\"].to(DEVICE)\n",
    "            aspect_labels = batch[\"aspect_labels\"].to(DEVICE)\n",
    "            aspect_masks = batch[\"aspect_masks\"].to(DEVICE)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits, rating_logits = model(input_ids, attn)\n",
    "                loss_acsa = masked_aspect_loss(logits, aspect_labels, aspect_masks, DEVICE)\n",
    "                loss = loss_acsa\n",
    "                # optional rating loss\n",
    "                if args.rating_head and \"star\" in batch:\n",
    "                    star = batch[\"star\"].to(DEVICE)  # assume 1..5 already int\n",
    "                    rating_loss_fn = nn.CrossEntropyLoss()\n",
    "                    loss_rating = rating_loss_fn(rating_logits, star - 1)  # convert to 0..4\n",
    "                    loss = loss + 0.2 * loss_rating\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if step % args.grad_accum == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                global_step += 1\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if step % 20 == 0:\n",
    "                pbar.set_postfix({\"loss\": running_loss / step})\n",
    "\n",
    "        # end epoch: evaluate\n",
    "        dev_loss, dev_f1, dev_acc = evaluate(model, dev_loader)\n",
    "        print(f\"Epoch {epoch} DEV loss {dev_loss:.4f} F1 {dev_f1:.4f} Acc {dev_acc:.4f}\")\n",
    "        # save best\n",
    "        if dev_f1 > best_dev_f1:\n",
    "            best_dev_f1 = dev_f1\n",
    "            ckpt_path = Path(args.save_dir) / \"best_teacher.pt\"\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict(),\n",
    "                \"args\": vars(args),\n",
    "                \"epoch\": epoch\n",
    "            }, ckpt_path)\n",
    "            print(\"Saved best model to\", ckpt_path)\n",
    "\n",
    "    # final test eval\n",
    "    print(\"Loading best model for TEST eval...\")\n",
    "    ckpt = torch.load(Path(args.save_dir) / \"best_teacher.pt\", map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    test_loss, test_f1, test_acc = evaluate(model, test_loader)\n",
    "    print(f\"TEST loss {test_loss:.4f} F1 {test_f1:.4f} Acc {test_acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c0a43",
   "metadata": {},
   "source": [
    "# student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a60e3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import argparse\n",
    "import torch.nn.functional as Fimport \n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import argparse\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Args / Config\n",
    "# -------------------------\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_pt\", type=str, default=r\"C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\asap_preprocessed.pt\")\n",
    "parser.add_argument(\"--teacher_ckpt\", type=str, default=\"./checkpoints_teacher/best_teacher.pt\")\n",
    "parser.add_argument(\"--teacher_model_name\", type=str, default=\"hfl/chinese-roberta-wwm-ext\")\n",
    "parser.add_argument(\"--student_model_name\", type=str, default=\"hfl/chinese-bert-wwm\")  #  valid student\n",
    "parser.add_argument(\"--max_len\", type=int, default=256)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--epochs\", type=int, default=8)   # train longer for small models\n",
    "parser.add_argument(\"--lr\", type=float, default=2e-5)\n",
    "parser.add_argument(\"--alpha\", type=float, default=0.3, help=\"weight for hard-label CE\")\n",
    "parser.add_argument(\"--beta\", type=float, default=0.7, help=\"weight for distillation KL\")\n",
    "parser.add_argument(\"--temp\", type=float, default=3.0, help=\"distillation temperature\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default=\"./checkpoints_student\")\n",
    "parser.add_argument(\"--precompute_teacher_logits\", action=\"store_true\", help=\"Recompute teacher logits if set\")\n",
    "args = parser.parse_args([])  # for Jupyter; use parser.parse_args() in CLI\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "ASPECTS = [\n",
    "    \"Location#Transportation\",\"Location#Downtown\",\"Location#Easy_to_find\",\n",
    "    \"Service#Queue\",\"Service#Hospitality\",\"Service#Parking\",\"Service#Timely\",\n",
    "    \"Price#Level\",\"Price#Cost_effective\",\"Price#Discount\",\n",
    "    \"Ambience#Decoration\",\"Ambience#Noise\",\"Ambience#Space\",\"Ambience#Sanitary\",\n",
    "    \"Food#Portion\",\"Food#Taste\",\"Food#Appearance\",\"Food#Recommend\"\n",
    "]\n",
    "NUM_ASPECTS = len(ASPECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ee7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset wrapper\n",
    "# -------------------------\n",
    "class ASAPDataset(Dataset):\n",
    "    def __init__(self, tensors, teacher_logits=None):\n",
    "        self.input_ids = tensors[\"input_ids\"]\n",
    "        self.attn = tensors[\"attention_mask\"]\n",
    "        self.aspect_labels = tensors[\"aspect_labels\"]\n",
    "        self.aspect_masks = tensors[\"aspect_masks\"]\n",
    "        self.star = tensors.get(\"star\", None)\n",
    "        self.teacher_logits = teacher_logits\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attn[idx],\n",
    "            \"aspect_labels\": self.aspect_labels[idx],\n",
    "            \"aspect_masks\": self.aspect_masks[idx].float()\n",
    "        }\n",
    "        if self.star is not None:\n",
    "            item[\"star\"] = self.star[idx]\n",
    "        if self.teacher_logits is not None:\n",
    "            item[\"teacher_logits\"] = self.teacher_logits[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "612a7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# -------------------------\n",
    "class AspectAttentionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_aspects=NUM_ASPECTS):\n",
    "        super().__init__()\n",
    "        cfg = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=cfg)\n",
    "        d = cfg.hidden_size\n",
    "        self.num_aspects = num_aspects\n",
    "\n",
    "        # attention pooling\n",
    "        self.W_a = nn.Linear(d, d)\n",
    "        self.omega = nn.Parameter(torch.randn(num_aspects, d) * 0.02)\n",
    "        self.W_p = nn.Linear(d, d)\n",
    "\n",
    "        # per-aspect classifiers\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(d, 3) for _ in range(num_aspects)])\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.W_a.weight); nn.init.zeros_(self.W_a.bias)\n",
    "        nn.init.xavier_uniform_(self.W_p.weight); nn.init.zeros_(self.W_p.bias)\n",
    "        for c in self.classifiers:\n",
    "            nn.init.xavier_uniform_(c.weight); nn.init.zeros_(c.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        seq = outputs.last_hidden_state  # (B, L, d)\n",
    "\n",
    "        Ma = torch.tanh(self.W_a(seq))\n",
    "        scores = torch.matmul(Ma, self.omega.t())  # (B, L, A)\n",
    "        scores = scores.permute(0, 2, 1)           # (B, A, L)\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        r = torch.einsum(\"bal,bld->bad\", attn_weights, seq)\n",
    "        r = torch.tanh(self.W_p(r))\n",
    "\n",
    "        logits = []\n",
    "        for i in range(self.num_aspects):\n",
    "            logits_i = self.classifiers[i](r[:, i, :])  # (B, 3)\n",
    "            logits.append(logits_i.unsqueeze(1))\n",
    "        return torch.cat(logits, dim=1)  # (B, A, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad4de4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses & Metrics\n",
    "# -------------------------\n",
    "def masked_ce_loss(logits, labels, masks):\n",
    "    B,A,C = logits.size()\n",
    "    logits_flat = logits.view(-1, C)\n",
    "    labels_flat = labels.view(-1)\n",
    "    masks_flat = masks.view(-1)\n",
    "    keep = masks_flat.nonzero(as_tuple=False).squeeze(1)\n",
    "    if keep.numel() == 0:\n",
    "        return torch.tensor(0.0, device=logits.device, requires_grad=True)\n",
    "    return nn.CrossEntropyLoss()(logits_flat[keep], labels_flat[keep])\n",
    "\n",
    "def masked_kl_loss(student_logits, teacher_logits, masks, T=2.0):\n",
    "    B,A,C = student_logits.size()\n",
    "    s = student_logits.view(-1, C)\n",
    "    t = teacher_logits.view(-1, C)\n",
    "    masks_flat = masks.view(-1)\n",
    "    keep = masks_flat.nonzero(as_tuple=False).squeeze(1)\n",
    "    if keep.numel() == 0:\n",
    "        return torch.tensor(0.0, device=student_logits.device, requires_grad=True)\n",
    "    s_k, t_k = s[keep], t[keep]\n",
    "    log_p_s = F.log_softmax(s_k / T, dim=-1)\n",
    "    q_t = F.softmax(t_k / T, dim=-1)\n",
    "    return F.kl_div(log_p_s, q_t, reduction=\"batchmean\") * (T*T)\n",
    "\n",
    "def masked_metrics(logits, labels, masks):\n",
    "    preds = logits.detach().cpu().numpy().argmax(axis=-1).reshape(-1)\n",
    "    labels_flat = labels.detach().cpu().numpy().reshape(-1)\n",
    "    masks_flat = masks.detach().cpu().numpy().reshape(-1)\n",
    "    keep = masks_flat == 1\n",
    "    if keep.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "    y_true, y_pred = labels_flat[keep], preds[keep]\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0), accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f828fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load data\n",
    "# -------------------------\n",
    "data = torch.load(args.data_pt)\n",
    "print(\"Loaded preprocessed data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0d2c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Teacher logits\n",
    "# -------------------------\n",
    "teacher_logits_path = Path(\"./teacher_logits.pt\")\n",
    "if args.precompute_teacher_logits or not teacher_logits_path.exists():\n",
    "    print(\"Computing teacher logits...\")\n",
    "    teacher = AspectAttentionModel(args.teacher_model_name)\n",
    "    ckpt = torch.load(args.teacher_ckpt, map_location=\"cpu\")\n",
    "    teacher.load_state_dict(ckpt[\"model_state\"])\n",
    "    teacher.to(DEVICE).eval()\n",
    "    def tensor_loader(tensors): return DataLoader(ASAPDataset(tensors), batch_size=args.batch_size)\n",
    "    logits_store = {}\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        loader = tensor_loader(data[split])\n",
    "        parts = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(loader, desc=f\"Teacher logits {split}\"):\n",
    "                input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "                attn = batch[\"attention_mask\"].to(DEVICE)\n",
    "                out = teacher(input_ids, attn)\n",
    "                parts.append(out.cpu())\n",
    "        logits_store[split] = torch.cat(parts, dim=0)\n",
    "    torch.save(logits_store, teacher_logits_path)\n",
    "    print(\"Saved teacher logits.\")\n",
    "else:\n",
    "    logits_store = torch.load(teacher_logits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adaf2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laksh\\miniconda3\\envs\\asap_light\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\laksh\\.cache\\huggingface\\hub\\models--hfl--chinese-bert-wwm. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "Epoch 1 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:43: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\generated\\python_variable_methods.cpp:836.)\n",
      "  pbar.set_postfix({\"loss\": float(loss)})\n",
      "Epoch 1 train: 100%|██████████| 1152/1152 [06:08<00:00,  3.13it/s, loss=0.663]\n",
      "Dev eval: 100%|██████████| 155/155 [00:36<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 DEV F1 0.6859 Acc 0.7728\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 2 train: 100%|██████████| 1152/1152 [06:07<00:00,  3.14it/s, loss=0.332]\n",
      "Dev eval: 100%|██████████| 155/155 [00:38<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 DEV F1 0.7315 Acc 0.8030\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 3 train: 100%|██████████| 1152/1152 [06:14<00:00,  3.08it/s, loss=0.359]\n",
      "Dev eval: 100%|██████████| 155/155 [00:38<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 DEV F1 0.7416 Acc 0.8088\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 4 train: 100%|██████████| 1152/1152 [06:13<00:00,  3.08it/s, loss=0.277]\n",
      "Dev eval: 100%|██████████| 155/155 [00:36<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 DEV F1 0.7469 Acc 0.8126\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 5 train: 100%|██████████| 1152/1152 [06:10<00:00,  3.11it/s, loss=0.367]\n",
      "Dev eval: 100%|██████████| 155/155 [00:39<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 DEV F1 0.7488 Acc 0.8133\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 6 train: 100%|██████████| 1152/1152 [06:16<00:00,  3.06it/s, loss=0.234]\n",
      "Dev eval: 100%|██████████| 155/155 [00:38<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 DEV F1 0.7485 Acc 0.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 7 train: 100%|██████████| 1152/1152 [06:16<00:00,  3.06it/s, loss=0.221]\n",
      "Dev eval: 100%|██████████| 155/155 [00:38<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 DEV F1 0.7496 Acc 0.8136\n",
      "Saved best student.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 train:   0%|          | 0/1152 [00:00<?, ?it/s]C:\\Users\\laksh\\AppData\\Local\\Temp\\ipykernel_8612\\530556117.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 8 train: 100%|██████████| 1152/1152 [06:14<00:00,  3.07it/s, loss=0.229]\n",
      "Dev eval: 100%|██████████| 155/155 [00:39<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 DEV F1 0.7501 Acc 0.8140\n",
      "Saved best student.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Student training\n",
    "# -------------------------\n",
    "train_ds = ASAPDataset(data[\"train\"], teacher_logits=logits_store[\"train\"])\n",
    "dev_ds   = ASAPDataset(data[\"dev\"], teacher_logits=logits_store[\"dev\"])\n",
    "test_ds  = ASAPDataset(data[\"test\"], teacher_logits=logits_store[\"test\"])\n",
    "train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_ds, batch_size=args.batch_size)\n",
    "test_loader  = DataLoader(test_ds, batch_size=args.batch_size)\n",
    "\n",
    "student = AspectAttentionModel(args.student_model_name)\n",
    "student.to(DEVICE)\n",
    "\n",
    "# optimizer & scheduler\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "params = [\n",
    "    {\"params\": [p for n,p in student.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
    "    {\"params\": [p for n,p in student.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = AdamW(params, lr=args.lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, int(len(train_loader)*0.06), len(train_loader)*args.epochs)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "best_dev_f1 = -1.0\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    student.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} train\")\n",
    "    for batch in pbar:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attn = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"aspect_labels\"].to(DEVICE)\n",
    "        masks = batch[\"aspect_masks\"].to(DEVICE).float()\n",
    "        t_logits = batch[\"teacher_logits\"].to(DEVICE)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            s_logits = student(input_ids, attn)\n",
    "            loss = args.alpha*masked_ce_loss(s_logits, labels, masks) + \\\n",
    "                   args.beta*masked_kl_loss(s_logits, t_logits, masks, T=args.temp)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        optimizer.zero_grad(); scheduler.step()\n",
    "        pbar.set_postfix({\"loss\": float(loss)})\n",
    "\n",
    "    # Eval\n",
    "    student.eval(); all_f1=[]; all_acc=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dev_loader, desc=\"Dev eval\"):\n",
    "            s_logits = student(batch[\"input_ids\"].to(DEVICE), batch[\"attention_mask\"].to(DEVICE))\n",
    "            f1, acc = masked_metrics(s_logits, batch[\"aspect_labels\"], batch[\"aspect_masks\"])\n",
    "            all_f1.append(f1); all_acc.append(acc)\n",
    "    mean_f1, mean_acc = np.mean(all_f1), np.mean(all_acc)\n",
    "    print(f\"Epoch {epoch} DEV F1 {mean_f1:.4f} Acc {mean_acc:.4f}\")\n",
    "    if mean_f1 > best_dev_f1:\n",
    "        best_dev_f1 = mean_f1\n",
    "        torch.save({\"model_state\": student.state_dict()}, Path(args.save_dir)/\"best_student.pt\")\n",
    "        print(\"Saved best student.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2732407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best student...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test eval: 100%|██████████| 155/155 [00:38<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST F1 0.7584004267446625 Acc 0.8197040954973617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Test Eval\n",
    "# -------------------------\n",
    "print(\"Loading best student...\")\n",
    "student.load_state_dict(torch.load(Path(args.save_dir)/\"best_student.pt\")[\"model_state\"])\n",
    "student.to(DEVICE).eval()\n",
    "all_f1=[]; all_acc=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test eval\"):\n",
    "        s_logits = student(batch[\"input_ids\"].to(DEVICE), batch[\"attention_mask\"].to(DEVICE))\n",
    "        f1, acc = masked_metrics(s_logits, batch[\"aspect_labels\"], batch[\"aspect_masks\"])\n",
    "        all_f1.append(f1); all_acc.append(acc)\n",
    "print(\"TEST F1\", np.mean(all_f1), \"Acc\", np.mean(all_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f606b",
   "metadata": {},
   "source": [
    "# error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0351ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b3b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# -------------------------\n",
    "DATA_PT = r\"C:\\Users\\laksh\\OneDrive\\Documents\\NLP\\data\\asap_preprocessed.pt\"\n",
    "BEST_STUDENT = \"./checkpoints_student/best_student.pt\"\n",
    "STUDENT_MODEL_NAME = \"hfl/chinese-bert-wwm\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ASPECTS = [\n",
    "    \"Location#Transportation\",\"Location#Downtown\",\"Location#Easy_to_find\",\n",
    "    \"Service#Queue\",\"Service#Hospitality\",\"Service#Parking\",\"Service#Timely\",\n",
    "    \"Price#Level\",\"Price#Cost_effective\",\"Price#Discount\",\n",
    "    \"Ambience#Decoration\",\"Ambience#Noise\",\"Ambience#Space\",\"Ambience#Sanitary\",\n",
    "    \"Food#Portion\",\"Food#Taste\",\"Food#Appearance\",\"Food#Recommend\"\n",
    "]\n",
    "NUM_ASPECTS = len(ASPECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3020b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset wrapper\n",
    "# -------------------------\n",
    "class ASAPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tensors):\n",
    "        self.input_ids = tensors[\"input_ids\"]\n",
    "        self.attn = tensors[\"attention_mask\"]\n",
    "        self.aspect_labels = tensors[\"aspect_labels\"]\n",
    "        self.aspect_masks = tensors[\"aspect_masks\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attn[idx],\n",
    "            \"aspect_labels\": self.aspect_labels[idx],\n",
    "            \"aspect_masks\": self.aspect_masks[idx].float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf94132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# -------------------------\n",
    "class AspectAttentionModel(nn.Module):\n",
    "    def __init__(self, model_name, num_aspects=NUM_ASPECTS):\n",
    "        super().__init__()\n",
    "        cfg = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name, config=cfg)\n",
    "        d = cfg.hidden_size\n",
    "        self.num_aspects = num_aspects\n",
    "\n",
    "        self.W_a = nn.Linear(d, d)\n",
    "        self.omega = nn.Parameter(torch.randn(num_aspects, d) * 0.02)\n",
    "        self.W_p = nn.Linear(d, d)\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(d, 3) for _ in range(num_aspects)])\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.W_a.weight); nn.init.zeros_(self.W_a.bias)\n",
    "        nn.init.xavier_uniform_(self.W_p.weight); nn.init.zeros_(self.W_p.bias)\n",
    "        for c in self.classifiers:\n",
    "            nn.init.xavier_uniform_(c.weight); nn.init.zeros_(c.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        seq = outputs.last_hidden_state\n",
    "        Ma = torch.tanh(self.W_a(seq))\n",
    "        scores = torch.matmul(Ma, self.omega.t())  # (B, L, A)\n",
    "        scores = scores.permute(0, 2, 1)           # (B, A, L)\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        r = torch.einsum(\"bal,bld->bad\", attn_weights, seq)\n",
    "        r = torch.tanh(self.W_p(r))\n",
    "\n",
    "        logits = []\n",
    "        for i in range(self.num_aspects):\n",
    "            logits_i = self.classifiers[i](r[:, i, :])  # (B, 3)\n",
    "            logits.append(logits_i.unsqueeze(1))\n",
    "        return torch.cat(logits, dim=1)  # (B, A, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8533cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading student model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AspectAttentionModel(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (W_a): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (W_p): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifiers): ModuleList(\n",
       "    (0-17): 18 x Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data & model\n",
    "# -------------------------\n",
    "print(\"Loading data...\")\n",
    "data = torch.load(DATA_PT)\n",
    "test_ds = ASAPDataset(data[\"test\"])\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "print(\"Loading student model...\")\n",
    "student = AspectAttentionModel(STUDENT_MODEL_NAME)\n",
    "ckpt = torch.load(BEST_STUDENT, map_location=DEVICE)\n",
    "student.load_state_dict(ckpt[\"model_state\"])\n",
    "student.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc3a5f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Performance ===\n",
      "Accuracy: 0.8195120231295395\n",
      "Macro F1: 0.7621880949318487\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# -------------------------\n",
    "all_preds, all_labels, all_masks = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attn = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"aspect_labels\"].cpu().numpy()\n",
    "        masks = batch[\"aspect_masks\"].cpu().numpy()\n",
    "\n",
    "        logits = student(input_ids, attn).cpu().numpy()\n",
    "        preds = logits.argmax(-1)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "        all_masks.append(masks)\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_masks = np.concatenate(all_masks, axis=0)\n",
    "\n",
    "# Flatten with mask\n",
    "mask_idx = all_masks.reshape(-1) == 1\n",
    "y_true = all_labels.reshape(-1)[mask_idx]\n",
    "y_pred = all_preds.reshape(-1)[mask_idx]\n",
    "\n",
    "# Overall\n",
    "print(\"\\n=== Overall Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a81ca29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-Aspect Performance ===\n",
      "Location#Transportation   | Acc: 0.933 | F1: 0.625\n",
      "Location#Downtown         | Acc: 0.960 | F1: 0.549\n",
      "Location#Easy_to_find     | Acc: 0.882 | F1: 0.718\n",
      "Service#Queue             | Acc: 0.699 | F1: 0.698\n",
      "Service#Hospitality       | Acc: 0.806 | F1: 0.723\n",
      "Service#Parking           | Acc: 0.739 | F1: 0.611\n",
      "Service#Timely            | Acc: 0.809 | F1: 0.701\n",
      "Price#Level               | Acc: 0.728 | F1: 0.731\n",
      "Price#Cost_effective      | Acc: 0.863 | F1: 0.696\n",
      "Price#Discount            | Acc: 0.734 | F1: 0.589\n",
      "Ambience#Decoration       | Acc: 0.868 | F1: 0.724\n",
      "Ambience#Noise            | Acc: 0.871 | F1: 0.777\n",
      "Ambience#Space            | Acc: 0.852 | F1: 0.797\n",
      "Ambience#Sanitary         | Acc: 0.871 | F1: 0.749\n",
      "Food#Portion              | Acc: 0.789 | F1: 0.694\n",
      "Food#Taste                | Acc: 0.794 | F1: 0.746\n",
      "Food#Appearance           | Acc: 0.810 | F1: 0.647\n",
      "Food#Recommend            | Acc: 0.882 | F1: 0.645\n"
     ]
    }
   ],
   "source": [
    "# Per-aspect\n",
    "print(\"\\n=== Per-Aspect Performance ===\")\n",
    "for i, aspect in enumerate(ASPECTS):\n",
    "    mask = all_masks[:, i] == 1\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "    y_t, y_p = all_labels[:, i][mask], all_preds[:, i][mask]\n",
    "    f1 = f1_score(y_t, y_p, average=\"macro\", zero_division=0)\n",
    "    acc = accuracy_score(y_t, y_p)\n",
    "    print(f\"{aspect:25s} | Acc: {acc:.3f} | F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76533166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for one aspect (example: Food#Taste)\n",
    "aspect_idx = ASPECTS.index(\"Food#Taste\")\n",
    "mask = all_masks[:, aspect_idx] == 1\n",
    "cm = confusion_matrix(all_labels[:, aspect_idx][mask], all_preds[:, aspect_idx][mask], labels=[0,1,2])\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=[\"Neg\",\"Neu\",\"Pos\"], yticklabels=[\"Neg\",\"Neu\",\"Pos\"], cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Food#Taste\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fc896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Misclassified Examples (Guaranteed to Show Errors) ===\n",
      "[TRUE: 1 | PRED: 2]\n",
      "[TRUE: 1 | PRED: 2]\n",
      "[TRUE: 1 | PRED: 2]\n",
      "[TRUE: 0 | PRED: 1]\n",
      "[TRUE: 1 | PRED: 2]\n",
      "[TRUE: 2 | PRED: 1]\n",
      "[TRUE: 2 | PRED: 1]\n",
      "[TRUE: 1 | PRED: 0]\n",
      "[TRUE: 1 | PRED: 0]\n",
      "[TRUE: 1 | PRED: 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "# Assuming 'y_true' and 'y_pred' are the flattened, masked arrays (from your original script)\n",
    "\n",
    "# --- 1. Find the indices of ALL misclassified predictions ---\n",
    "misclassified_indices = np.where(y_true != y_pred)[0]\n",
    "\n",
    "# --- 2. Determine how many to display (e.g., 10 or fewer if the error rate is very low) ---\n",
    "num_to_display = min(10, len(misclassified_indices))\n",
    "\n",
    "# --- 3. Sample indices from the misclassified set ---\n",
    "if num_to_display > 0:\n",
    "    sample_indices = random.sample(list(misclassified_indices), num_to_display)\n",
    "    \n",
    "    print(\"\\n=== Misclassified Examples (Guaranteed to Show Errors) ===\")\n",
    "    \n",
    "    # Iterate over the sampled indices to display the error\n",
    "    for flat_index in sample_indices:\n",
    "        true_label = y_true[flat_index]\n",
    "        pred_label = y_pred[flat_index]\n",
    "        \n",
    "        # To display the review text, you need to map the flat index back \n",
    "        # to the original batch and aspect, which is complex.\n",
    "        \n",
    "        # For simplicity in output, print the error type:\n",
    "        print(f\"[TRUE: {true_label} | PRED: {pred_label}]\")\n",
    "else:\n",
    "    print(\"\\n=== Misclassified Examples ===\\n(No errors found in the Test set - Unlikely, but possible.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6c78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asap_light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
